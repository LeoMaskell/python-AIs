{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11957955",
   "metadata": {},
   "source": [
    "# ai with pytorch for detecting heart disease in humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a377b0",
   "metadata": {},
   "source": [
    "## import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70bb76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd75cb",
   "metadata": {},
   "source": [
    "## dataset stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51917f55",
   "metadata": {},
   "source": [
    "### import dataset csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b31add1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
       "37    57     1    4        150    276     0         2       112       1   \n",
       "71    67     1    4        125    254     1         0       163       0   \n",
       "132   29     1    2        130    204     0         2       202       0   \n",
       "137   62     1    2        120    281     0         2       103       0   \n",
       "5     56     1    2        120    236     0         0       178       0   \n",
       "..   ...   ...  ...        ...    ...   ...       ...       ...     ...   \n",
       "145   47     1    3        108    243     0         0       152       0   \n",
       "212   41     1    3        130    214     0         2       168       0   \n",
       "258   70     1    2        156    245     0         2       143       0   \n",
       "280   57     1    4        110    335     0         0       143       1   \n",
       "65    60     1    4        145    282     0         2       142       1   \n",
       "\n",
       "      oldpeak   slope   ca  thal   diagnosis  \n",
       "37        0.6       2  1.0   6.0           1  \n",
       "71        0.2       2  2.0   7.0           3  \n",
       "132       0.0       1  0.0   3.0           0  \n",
       "137       1.4       2  1.0   7.0           3  \n",
       "5         0.8       1  0.0   3.0           0  \n",
       "..        ...     ...  ...   ...         ...  \n",
       "145       0.0       1  0.0   3.0           1  \n",
       "212       2.0       2  0.0   3.0           0  \n",
       "258       0.0       1  0.0   3.0           0  \n",
       "280       3.0       2  1.0   7.0           2  \n",
       "65        2.8       2  2.0   7.0           2  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "#show table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e5e99",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3daa9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
      "37    57     1    4        150    276     0         2       112       1   \n",
      "71    67     1    4        125    254     1         0       163       0   \n",
      "132   29     1    2        130    204     0         2       202       0   \n",
      "137   62     1    2        120    281     0         2       103       0   \n",
      "5     56     1    2        120    236     0         0       178       0   \n",
      "..   ...   ...  ...        ...    ...   ...       ...       ...     ...   \n",
      "145   47     1    3        108    243     0         0       152       0   \n",
      "212   41     1    3        130    214     0         2       168       0   \n",
      "258   70     1    2        156    245     0         2       143       0   \n",
      "280   57     1    4        110    335     0         0       143       1   \n",
      "65    60     1    4        145    282     0         2       142       1   \n",
      "\n",
      "      oldpeak   slope   ca  thal   diagnosis  \n",
      "37        0.6       2  1.0   6.0           1  \n",
      "71        0.2       2  2.0   7.0           3  \n",
      "132       0.0       1  0.0   3.0           0  \n",
      "137       1.4       2  1.0   7.0           3  \n",
      "5         0.8       1  0.0   3.0           0  \n",
      "..        ...     ...  ...   ...         ...  \n",
      "145       0.0       1  0.0   3.0           1  \n",
      "212       2.0       2  0.0   3.0           0  \n",
      "258       0.0       1  0.0   3.0           0  \n",
      "280       3.0       2  1.0   7.0           2  \n",
      "65        2.8       2  2.0   7.0           2  \n",
      "\n",
      "[303 rows x 14 columns]\n",
      "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
      "37    57     1    4        150    276     0         2       112       1   \n",
      "71    67     1    4        125    254     1         0       163       0   \n",
      "132   29     1    2        130    204     0         2       202       0   \n",
      "137   62     1    2        120    281     0         2       103       0   \n",
      "5     56     1    2        120    236     0         0       178       0   \n",
      "..   ...   ...  ...        ...    ...   ...       ...       ...     ...   \n",
      "76    60     1    4        125    258     0         2       141       1   \n",
      "189   69     1    3        140    254     0         2       146       0   \n",
      "178   43     1    3        130    315     0         0       162       0   \n",
      "62    58     1    4        128    216     0         2       131       1   \n",
      "145   47     1    3        108    243     0         0       152       0   \n",
      "\n",
      "      oldpeak   slope   ca  thal   diagnosis  \n",
      "37        0.6       2  1.0   6.0           1  \n",
      "71        0.2       2  2.0   7.0           3  \n",
      "132       0.0       1  0.0   3.0           0  \n",
      "137       1.4       2  1.0   7.0           3  \n",
      "5         0.8       1  0.0   3.0           0  \n",
      "..        ...     ...  ...   ...         ...  \n",
      "76        2.8       2  1.0   7.0           1  \n",
      "189       2.0       2  3.0   7.0           2  \n",
      "178       1.9       1  1.0   3.0           0  \n",
      "62        2.2       2  3.0   7.0           1  \n",
      "145       0.0       1  0.0   3.0           1  \n",
      "\n",
      "[299 rows x 14 columns]\n",
      "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
      "212   41     1    3        130    214     0         2       168       0   \n",
      "258   70     1    2        156    245     0         2       143       0   \n",
      "280   57     1    4        110    335     0         0       143       1   \n",
      "65    60     1    4        145    282     0         2       142       1   \n",
      "\n",
      "      oldpeak   slope   ca  thal   diagnosis  \n",
      "212       2.0       2  0.0   3.0           0  \n",
      "258       0.0       1  0.0   3.0           0  \n",
      "280       3.0       2  1.0   7.0           2  \n",
      "65        2.8       2  2.0   7.0           2  \n",
      "[[57 1 4 ... '1.0' '6.0' 1]\n",
      " [67 1 4 ... '2.0' '7.0' 3]\n",
      " [29 1 2 ... '0.0' '3.0' 0]\n",
      " ...\n",
      " [43 1 3 ... '1.0' '3.0' 0]\n",
      " [58 1 4 ... '3.0' '7.0' 1]\n",
      " [47 1 3 ... '0.0' '3.0' 1]]\n",
      "[[41 1 3 130 214 0 2 168 0 2.0 2 '0.0' '3.0' 0]\n",
      " [70 1 2 156 245 0 2 143 0 0.0 1 '0.0' '3.0' 0]\n",
      " [57 1 4 110 335 0 0 143 1 3.0 2 '1.0' '7.0' 2]\n",
      " [60 1 4 145 282 0 2 142 1 2.8 2 '2.0' '7.0' 2]]\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.99\n",
    "total_rows = df.shape[0]\n",
    "train_size = int(total_rows*ratio)\n",
    "\n",
    "# Split data into a test dataset and train dataset\n",
    "train = df[0:train_size]\n",
    "test = df[train_size:]\n",
    "\n",
    "#convert to numpy arrays (so its autodiff compatible)\n",
    "train_data = train.to_numpy()\n",
    "test_data = test.to_numpy()\n",
    "\n",
    "#check\n",
    "print(df)\n",
    "\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72481c8e",
   "metadata": {},
   "source": [
    "## acc. ai stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd88dd",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a1b32",
   "metadata": {},
   "source": [
    "- using pytorch, numpy, and matplotlib (probably:) )\n",
    "- using a high train test split ratio to get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bec256c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module): \n",
    "  def __init__(self): \n",
    "    super(SimpleNN, self).__init__() \n",
    "    self.fc1 = nn.Linear(13, 2)  # match 13 input features from your input\n",
    "    self.relu = nn.ReLU()      # Activation function \n",
    "    self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "  def forward(self, x): \n",
    "    x = self.fc1(x) \n",
    "    x = self.relu(x) \n",
    "    x = self.fc2(x) \n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14474157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=13, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN() \n",
    "\n",
    "# outputs the struct. of the model\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4222ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data for training\n",
    "train.columns = train.columns.str.strip()               # clean column name\n",
    "inputs = train.drop(\"diagnosis\", axis=1)                # Drop target column\n",
    "inputs = inputs.apply(pd.to_numeric, errors='coerce')   # Convert all values to numeric, set errors='coerce' to handle '?'\n",
    "inputs = inputs.fillna(inputs.mean())  # Fill NaNs with 0, safer than fillna(0)\n",
    "inputs = torch.tensor(inputs.values)\n",
    "\n",
    "# Process targets (assuming 'M'/'B' or similar)\n",
    "targets = train[\"diagnosis\"].map({\"M\": 1, \"B\": 0})\n",
    "targets = torch.tensor(targets.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f96bbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b641a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean squared error\n",
    "criterion = nn.MSELoss() \n",
    "optimiser = optim.SGD(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9da95c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs dtype: torch.float64\n",
      "targets dtype: torch.float64\n",
      "model parameter dtype: torch.float32\n",
      "Epoch [1/100], Loss: nan\n",
      "Epoch [2/100], Loss: nan\n",
      "Epoch [3/100], Loss: nan\n",
      "Epoch [4/100], Loss: nan\n",
      "Epoch [5/100], Loss: nan\n",
      "Epoch [6/100], Loss: nan\n",
      "Epoch [7/100], Loss: nan\n",
      "Epoch [8/100], Loss: nan\n",
      "Epoch [9/100], Loss: nan\n",
      "Epoch [10/100], Loss: nan\n",
      "Epoch [11/100], Loss: nan\n",
      "Epoch [12/100], Loss: nan\n",
      "Epoch [13/100], Loss: nan\n",
      "Epoch [14/100], Loss: nan\n",
      "Epoch [15/100], Loss: nan\n",
      "Epoch [16/100], Loss: nan\n",
      "Epoch [17/100], Loss: nan\n",
      "Epoch [18/100], Loss: nan\n",
      "Epoch [19/100], Loss: nan\n",
      "Epoch [20/100], Loss: nan\n",
      "Epoch [21/100], Loss: nan\n",
      "Epoch [22/100], Loss: nan\n",
      "Epoch [23/100], Loss: nan\n",
      "Epoch [24/100], Loss: nan\n",
      "Epoch [25/100], Loss: nan\n",
      "Epoch [26/100], Loss: nan\n",
      "Epoch [27/100], Loss: nan\n",
      "Epoch [28/100], Loss: nan\n",
      "Epoch [29/100], Loss: nan\n",
      "Epoch [30/100], Loss: nan\n",
      "Epoch [31/100], Loss: nan\n",
      "Epoch [32/100], Loss: nan\n",
      "Epoch [33/100], Loss: nan\n",
      "Epoch [34/100], Loss: nan\n",
      "Epoch [35/100], Loss: nan\n",
      "Epoch [36/100], Loss: nan\n",
      "Epoch [37/100], Loss: nan\n",
      "Epoch [38/100], Loss: nan\n",
      "Epoch [39/100], Loss: nan\n",
      "Epoch [40/100], Loss: nan\n",
      "Epoch [41/100], Loss: nan\n",
      "Epoch [42/100], Loss: nan\n",
      "Epoch [43/100], Loss: nan\n",
      "Epoch [44/100], Loss: nan\n",
      "Epoch [45/100], Loss: nan\n",
      "Epoch [46/100], Loss: nan\n",
      "Epoch [47/100], Loss: nan\n",
      "Epoch [48/100], Loss: nan\n",
      "Epoch [49/100], Loss: nan\n",
      "Epoch [50/100], Loss: nan\n",
      "Epoch [51/100], Loss: nan\n",
      "Epoch [52/100], Loss: nan\n",
      "Epoch [53/100], Loss: nan\n",
      "Epoch [54/100], Loss: nan\n",
      "Epoch [55/100], Loss: nan\n",
      "Epoch [56/100], Loss: nan\n",
      "Epoch [57/100], Loss: nan\n",
      "Epoch [58/100], Loss: nan\n",
      "Epoch [59/100], Loss: nan\n",
      "Epoch [60/100], Loss: nan\n",
      "Epoch [61/100], Loss: nan\n",
      "Epoch [62/100], Loss: nan\n",
      "Epoch [63/100], Loss: nan\n",
      "Epoch [64/100], Loss: nan\n",
      "Epoch [65/100], Loss: nan\n",
      "Epoch [66/100], Loss: nan\n",
      "Epoch [67/100], Loss: nan\n",
      "Epoch [68/100], Loss: nan\n",
      "Epoch [69/100], Loss: nan\n",
      "Epoch [70/100], Loss: nan\n",
      "Epoch [71/100], Loss: nan\n",
      "Epoch [72/100], Loss: nan\n",
      "Epoch [73/100], Loss: nan\n",
      "Epoch [74/100], Loss: nan\n",
      "Epoch [75/100], Loss: nan\n",
      "Epoch [76/100], Loss: nan\n",
      "Epoch [77/100], Loss: nan\n",
      "Epoch [78/100], Loss: nan\n",
      "Epoch [79/100], Loss: nan\n",
      "Epoch [80/100], Loss: nan\n",
      "Epoch [81/100], Loss: nan\n",
      "Epoch [82/100], Loss: nan\n",
      "Epoch [83/100], Loss: nan\n",
      "Epoch [84/100], Loss: nan\n",
      "Epoch [85/100], Loss: nan\n",
      "Epoch [86/100], Loss: nan\n",
      "Epoch [87/100], Loss: nan\n",
      "Epoch [88/100], Loss: nan\n",
      "Epoch [89/100], Loss: nan\n",
      "Epoch [90/100], Loss: nan\n",
      "Epoch [91/100], Loss: nan\n",
      "Epoch [92/100], Loss: nan\n",
      "Epoch [93/100], Loss: nan\n",
      "Epoch [94/100], Loss: nan\n",
      "Epoch [95/100], Loss: nan\n",
      "Epoch [96/100], Loss: nan\n",
      "Epoch [97/100], Loss: nan\n",
      "Epoch [98/100], Loss: nan\n",
      "Epoch [99/100], Loss: nan\n",
      "Epoch [100/100], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([299])) that is different to the input size (torch.Size([299, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"inputs dtype: {inputs.dtype}\")\n",
    "print(f\"targets dtype: {targets.dtype}\")\n",
    "print(f\"model parameter dtype: {next(model.parameters()).dtype}\")\n",
    "\n",
    "#sorting datatypes...\n",
    "inputs = inputs.float()\n",
    "targets = targets.float()\n",
    "model = model.float()\n",
    "\n",
    "for epoch in range(100):                 # Training for 5 epochs \n",
    "  optimiser.zero_grad()                  # Clear previous gradients \n",
    "  outputs = model(inputs)                # Forward pass \n",
    "  loss = criterion(outputs, targets)     # Calculate loss \n",
    "  loss.backward()                        # Backward pass to compute gradients \n",
    "  optimiser.step()                       # Update weights \n",
    "  print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}') \n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
