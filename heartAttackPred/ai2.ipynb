{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11957955",
   "metadata": {},
   "source": [
    "# ai with pytorch for detecting heart disease in humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a377b0",
   "metadata": {},
   "source": [
    "## import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70bb76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd75cb",
   "metadata": {},
   "source": [
    "## dataset stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51917f55",
   "metadata": {},
   "source": [
    "### import dataset csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b31add1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
       "251   58     1    4        146    218     0         0       105       0   \n",
       "14    52     1    3        172    199     1         0       162       0   \n",
       "219   59     1    4        138    271     0         2       182       0   \n",
       "55    54     1    4        124    266     0         2       109       1   \n",
       "163   58     0    4        100    248     0         2       122       0   \n",
       "..   ...   ...  ...        ...    ...   ...       ...       ...     ...   \n",
       "118   63     1    4        130    330     1         2       132       1   \n",
       "79    58     1    4        150    270     0         2       111       1   \n",
       "114   62     0    3        130    263     0         0        97       0   \n",
       "81    53     0    4        130    264     0         2       143       0   \n",
       "43    59     1    3        150    212     1         0       157       0   \n",
       "\n",
       "      oldpeak   slope   ca  thal   diagnosis  \n",
       "251       2.0       2  1.0   7.0           1  \n",
       "14        0.5       1  0.0   7.0           0  \n",
       "219       0.0       1  0.0   3.0           0  \n",
       "55        2.2       2  1.0   7.0           1  \n",
       "163       1.0       2  0.0   3.0           0  \n",
       "..        ...     ...  ...   ...         ...  \n",
       "118       1.8       1  3.0   7.0           3  \n",
       "79        0.8       1  0.0   7.0           3  \n",
       "114       1.2       2  1.0   7.0           2  \n",
       "81        0.4       2  0.0   3.0           0  \n",
       "43        1.6       1  0.0   3.0           0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "#show table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e5e99",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3daa9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
      "251   58     1    4        146    218     0         0       105       0   \n",
      "14    52     1    3        172    199     1         0       162       0   \n",
      "219   59     1    4        138    271     0         2       182       0   \n",
      "55    54     1    4        124    266     0         2       109       1   \n",
      "163   58     0    4        100    248     0         2       122       0   \n",
      "..   ...   ...  ...        ...    ...   ...       ...       ...     ...   \n",
      "118   63     1    4        130    330     1         2       132       1   \n",
      "79    58     1    4        150    270     0         2       111       1   \n",
      "114   62     0    3        130    263     0         0        97       0   \n",
      "81    53     0    4        130    264     0         2       143       0   \n",
      "43    59     1    3        150    212     1         0       157       0   \n",
      "\n",
      "      oldpeak   slope   ca  thal   diagnosis  \n",
      "251       2.0       2  1.0   7.0           1  \n",
      "14        0.5       1  0.0   7.0           0  \n",
      "219       0.0       1  0.0   3.0           0  \n",
      "55        2.2       2  1.0   7.0           1  \n",
      "163       1.0       2  0.0   3.0           0  \n",
      "..        ...     ...  ...   ...         ...  \n",
      "118       1.8       1  3.0   7.0           3  \n",
      "79        0.8       1  0.0   7.0           3  \n",
      "114       1.2       2  1.0   7.0           2  \n",
      "81        0.4       2  0.0   3.0           0  \n",
      "43        1.6       1  0.0   3.0           0  \n",
      "\n",
      "[303 rows x 14 columns]\n",
      "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
      "251   58     1    4        146    218     0         0       105       0   \n",
      "14    52     1    3        172    199     1         0       162       0   \n",
      "219   59     1    4        138    271     0         2       182       0   \n",
      "55    54     1    4        124    266     0         2       109       1   \n",
      "163   58     0    4        100    248     0         2       122       0   \n",
      "..   ...   ...  ...        ...    ...   ...       ...       ...     ...   \n",
      "268   40     1    4        152    223     0         0       181       0   \n",
      "28    43     1    4        150    247     0         0       171       0   \n",
      "249   62     1    2        128    208     1         2       140       0   \n",
      "240   41     1    2        110    235     0         0       153       0   \n",
      "118   63     1    4        130    330     1         2       132       1   \n",
      "\n",
      "      oldpeak   slope   ca  thal   diagnosis  \n",
      "251       2.0       2  1.0   7.0           1  \n",
      "14        0.5       1  0.0   7.0           0  \n",
      "219       0.0       1  0.0   3.0           0  \n",
      "55        2.2       2  1.0   7.0           1  \n",
      "163       1.0       2  0.0   3.0           0  \n",
      "..        ...     ...  ...   ...         ...  \n",
      "268       0.0       1  0.0   7.0           1  \n",
      "28        1.5       1  0.0   3.0           0  \n",
      "249       0.0       1  0.0   3.0           0  \n",
      "240       0.0       1  0.0   3.0           0  \n",
      "118       1.8       1  3.0   7.0           3  \n",
      "\n",
      "[299 rows x 14 columns]\n",
      "     age   sex   cp   trestbps   chol   fbs   restecg   thalach   exang  \\\n",
      "79    58     1    4        150    270     0         2       111       1   \n",
      "114   62     0    3        130    263     0         0        97       0   \n",
      "81    53     0    4        130    264     0         2       143       0   \n",
      "43    59     1    3        150    212     1         0       157       0   \n",
      "\n",
      "      oldpeak   slope   ca  thal   diagnosis  \n",
      "79        0.8       1  0.0   7.0           3  \n",
      "114       1.2       2  1.0   7.0           2  \n",
      "81        0.4       2  0.0   3.0           0  \n",
      "43        1.6       1  0.0   3.0           0  \n",
      "[[58 1 4 ... '1.0' '7.0' 1]\n",
      " [52 1 3 ... '0.0' '7.0' 0]\n",
      " [59 1 4 ... '0.0' '3.0' 0]\n",
      " ...\n",
      " [62 1 2 ... '0.0' '3.0' 0]\n",
      " [41 1 2 ... '0.0' '3.0' 0]\n",
      " [63 1 4 ... '3.0' '7.0' 3]]\n",
      "[[58 1 4 150 270 0 2 111 1 0.8 1 '0.0' '7.0' 3]\n",
      " [62 0 3 130 263 0 0 97 0 1.2 2 '1.0' '7.0' 2]\n",
      " [53 0 4 130 264 0 2 143 0 0.4 2 '0.0' '3.0' 0]\n",
      " [59 1 3 150 212 1 0 157 0 1.6 1 '0.0' '3.0' 0]]\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.99\n",
    "total_rows = df.shape[0]\n",
    "train_size = int(total_rows*ratio)\n",
    "\n",
    "# Split data into a test dataset and train dataset\n",
    "train = df[0:train_size]\n",
    "test = df[train_size:]\n",
    "\n",
    "#convert to numpy arrays (so its autodiff compatible)\n",
    "train_data = train.to_numpy()\n",
    "test_data = test.to_numpy()\n",
    "\n",
    "#check\n",
    "print(df)\n",
    "\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72481c8e",
   "metadata": {},
   "source": [
    "## acc. ai stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd88dd",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a1b32",
   "metadata": {},
   "source": [
    "- using pytorch, numpy, and matplotlib (probably:) )\n",
    "- using a high train test split ratio to get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bec256c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module): \n",
    "  def __init__(self): \n",
    "    super(SimpleNN, self).__init__() \n",
    "    self.fc1 = nn.Linear(13, 2)  # match 13 input features from your input\n",
    "    self.relu = nn.ReLU()      # Activation function \n",
    "    self.fc2 = nn.Linear(2, 1)\n",
    "\n",
    "  def forward(self, x): \n",
    "    x = self.fc1(x) \n",
    "    x = self.relu(x) \n",
    "    x = self.fc2(x) \n",
    "    return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14474157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=13, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN() \n",
    "\n",
    "# outputs the struct. of the model\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4222ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data for training\n",
    "train.columns = train.columns.str.strip()               # clean column name\n",
    "inputs = train.drop(\"diagnosis\", axis=1)                # Drop target column\n",
    "inputs = inputs.apply(pd.to_numeric, errors='coerce')   # Convert all values to numeric, set errors='coerce' to handle '?'\n",
    "inputs = inputs.fillna(inputs.mean())  # Fill NaNs with 0, safer than fillna(0)\n",
    "inputs = torch.tensor(inputs.values)\n",
    "\n",
    "# Process targets (assuming 'M'/'B' or similar)\n",
    "targets = train[\"diagnosis\"].map({\"M\": 1, \"B\": 0})\n",
    "targets = torch.tensor(targets.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f96bbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b641a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean squared error\n",
    "criterion = nn.MSELoss() \n",
    "optimiser = optim.SGD(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9da95c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs dtype: torch.float32\n",
      "targets dtype: torch.float32\n",
      "model parameter dtype: torch.float32\n",
      "torch.float32 torch.float32\n",
      "torch.Size([299, 13]) torch.Size([299, 1])\n",
      "Epoch [1/1000], Loss: nan\n",
      "Loss is NaN!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "print(f\"inputs dtype: {inputs.dtype}\")\n",
    "print(f\"targets dtype: {targets.dtype}\")\n",
    "print(f\"model parameter dtype: {next(model.parameters()).dtype}\")\n",
    "\n",
    "#sorting datatypes...\n",
    "inputs = inputs.float()\n",
    "targets = targets.float()\n",
    "model = model.float()\n",
    "\n",
    "# Make sure data types match\n",
    "inputs = inputs.float()\n",
    "targets = targets.float().view(-1, 1)  # Ensure shape matches model output\n",
    "\n",
    "# Sanity check\n",
    "print(inputs.dtype, targets.dtype)  # should both be float32\n",
    "print(inputs.shape, targets.shape)  # e.g., [299, 13] and [299, 1]\n",
    "\n",
    "for epoch in range(1000):                 # Training for 5 epochs \n",
    "  optimiser.zero_grad()                  # Clear previous gradients \n",
    "  outputs = model(inputs)                # Forward pass \n",
    "  loss = criterion(outputs, targets)     # Calculate loss \n",
    "  loss.backward()                        # Backward pass to compute gradients \n",
    "  optimiser.step()                       # Update weights \n",
    "  print(f'Epoch [{epoch + 1}/1000], Loss: {loss.item():.4f}')\n",
    "  if torch.isnan(loss):\n",
    "    print(\"Loss is NaN!\")\n",
    "    break \n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
